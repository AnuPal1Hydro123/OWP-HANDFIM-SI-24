{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d36404",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Created by Anupal Baruah, Post Doc, SDML , UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c383be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your AWS credentials and region\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = '--------'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '--------'\n",
    "os.environ['AWS_DEFAULT_REGION'] = '-------'\n",
    "\n",
    "# Verify that the environment variables are set correctly\n",
    "\n",
    "print(\"AWS Access Key:\", os.environ.get('AWS_ACCESS_KEY_ID'))\n",
    "print(\"AWS Secret Access Key:\", os.environ.get('AWS_SECRET_ACCESS_KEY'))\n",
    "print(\"AWS Default Region:\", os.environ.get('AWS_DEFAULT_REGION'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97af651",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the content of AWS S3 bucket\n",
    "\n",
    "!aws s3 ls s3://noaa-nws-owp-fim/hand_fim/fim_4_4_0_0/ --request-payer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413e7a3",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Download the sample_inputs data from the AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13443a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://noaa-nws-owp-fim/hand_fim/sample_inputs /Users/abaruah/Documents/HAND_Mac/sample_inputs --request-payer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8928b0",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Run the AWS CLI command to download your AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87259a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://noaa-nws-owp-fim/hand_fim/fim_4_4_0_0/12090301 /Users/abaruah/Documents/HAND_Mac/12090301 --request-payer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHeck the git version\n",
    "!git --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1baad",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clone from the git hub from this branch \"dev-whitebox-2.3.4\" to ignore the whitebox error. You need to comment line 103 to 118 in the dockerfile if not commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6150f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NOAA-OWP/inundation-mapping.git /Users/abaruah/Documents/HAND_Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8bc7f5",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build the docker image from the Dockerfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_name = \"sample_inputs\"\n",
    "tag = \"latest\"\n",
    "path_to_repository = \"/Users/abaruah/Documents/HAND_Mac/inundation-mapping/\"\n",
    "\n",
    "os.chdir(path_to_repository)\n",
    "\n",
    "docker_build_command = f\"docker build -f Dockerfile -t {image_name}:{tag} .\"\n",
    "\n",
    "!{docker_build_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09f47f",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preaparing the feature_id file from the hydrotable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dd9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hydrotable_ = pd.read_csv(r'/Users/abaruah/Documents/HAND_Mac/12090301/hydrotable.csv')\n",
    "\n",
    "unique_feature_ids = hydrotable_['feature_id'].drop_duplicates()\n",
    "\n",
    "\n",
    "unique_feature_ids_df = pd.DataFrame(unique_feature_ids, columns=['feature_id'])\n",
    "\n",
    "\n",
    "print(unique_feature_ids_df.head())\n",
    "\n",
    "\n",
    "unique_feature_ids_df.to_csv(r'/Users/abaruah/Documents/HAND_Mac/feature_id_12090301.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af58977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import fsspec\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir=r'/Users/abaruah/Documents/HAND_Mac'\n",
    "file_name='feature_id_12090301.csv'\n",
    "file_path=os.path.join(out_dir,file_name)\n",
    "fid_12090301=pd.read_csv(file_path)\n",
    "#print(fid_12090301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install xarray zarr fsspec s3fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37871fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=True)\n",
    "_file = fs.glob('noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr')\n",
    "\n",
    "ds = xr.open_dataset(fs.get_mapper(_file[0]), engine='zarr', backend_kwargs={'consolidated': True})\n",
    "#print(ds)\n",
    "\n",
    "\n",
    "\n",
    "# # October 2017\n",
    "s_date = '2016-10-09T14:00'\n",
    "e_date = '2016-10-09T16:00'\n",
    "\n",
    "ds2 = ds.sel(time=slice(s_date, e_date))\n",
    "\n",
    "directory_name='02050301_OCt_2016flood'\n",
    "\n",
    "discharge_dir = os.path.join(out_dir + '/' + '02050301_OCt_2016flood/')\n",
    "\n",
    "os.makedirs(discharge_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directory created at: {discharge_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in fid_12090301.iterrows():\n",
    "    feature_id = row['feature_id']\n",
    "    try:\n",
    "        Forecast_point = ds2['streamflow'].sel(feature_id=int(feature_id))\n",
    "        #print(Forecast_point)\n",
    "\n",
    "        Forecast_point = Forecast_point.to_pandas().to_frame()\n",
    "        Forecast_point.columns = [feature_id]\n",
    "        #print(Forecast_point)\n",
    "\n",
    "        Forecast_point.to_csv(os.path.join(discharge_dir, str(feature_id) + '.csv'))\n",
    "\n",
    "    except:\n",
    "        print('\\nError with station row : ', index, ' | Feature ID : ', feature_id)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "folder_path = r'/Users/abaruah/Documents/HAND_Mac/12090301_OCt_2016flood'\n",
    "\n",
    "\n",
    "concatenated_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "         file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "\n",
    "         df = pd.read_csv(file_path, encoding='latin-1')\n",
    "        \n",
    "#         # Extract the discharge column and use the filename as the header\n",
    "         header = os.path.splitext(filename)[0]  # Use filename without extension as header\n",
    "         df = df.rename(columns={'discharge': header})\n",
    "        \n",
    "#         # Add the data to the concatenated DataFrame\n",
    "         concatenated_data = pd.concat([concatenated_data, df], axis=1)\n",
    "\n",
    "\n",
    "concatenated_data = concatenated_data.loc[:,~concatenated_data.columns.duplicated()]\n",
    "\n",
    "\n",
    "\n",
    "output_file_path = os.path.join(folder_path, '12090301_InputHANDFIM.csv')\n",
    "concatenated_data.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the second CSV file (xyz.csv)\n",
    "xyz_df = pd.read_csv(r'/Users/abaruah/Documents/HAND_Mac/12090301_OCt_2016flood/12090301_InputHANDFIM.csv')\n",
    "\n",
    "\n",
    "transposed_row = xyz_df.iloc[0].transpose()\n",
    "\n",
    "\n",
    "transposed_row_df = transposed_row.to_frame().reset_index()\n",
    "\n",
    "\n",
    "transposed_row_df.columns = ['feature_id', 'discharge']\n",
    "\n",
    "transposed_row_df = transposed_row_df.drop(index=0).reset_index(drop=True)\n",
    "\n",
    "print(transposed_row_df)\n",
    "transposed_row_df.to_csv(r'/Users/abaruah/Documents/HAND_Mac/12090301_1stthhour.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e45ca7",
   "metadata": {},
   "source": [
    "# Create a blank folder 'Data' and within the 'Data' folder create sub-folder 'Inputs'. Copy and paste the contents from the sample inputs to 'Inputs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06c48a",
   "metadata": {},
   "source": [
    "# Keep the 12090301_1sthour.csv in the rating_curve folder within the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9bc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Running the container in detach mode\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "container_name = \"new_run\"\n",
    "image_name = \"sample_inputs\"\n",
    "tag = \"latest\"\n",
    "volumes = [\n",
    "    \"/Users/abaruah/Documents/HAND_Mac/inundation-mapping/:/foss_fim\",\n",
    "    \"/Users/abaruah/Documents/HAND_Mac/output/:/outputs\",\n",
    "    \"/Users/abaruah/Documents/HAND_Mac/Outputs_temp/:/fim_temp\",\n",
    "    \"/Users/abaruah/Documents/HAND_Mac/Data/:/data\"\n",
    "]\n",
    "\n",
    "volume_args = \" \".join([f\"-v {volume}\" for volume in volumes])\n",
    "\n",
    "# Docker run command in detached mode (-d) with a long-running process\n",
    "docker_run_command = f\"docker run -d --name {container_name} {volume_args} {image_name}:{tag} tail -f /dev/null\"\n",
    "\n",
    "# Print the command \n",
    "print(\"Running command:\", docker_run_command)\n",
    "\n",
    "# Execute the command to run the container\n",
    "result = subprocess.run(docker_run_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Print the output and error (if any)\n",
    "print(result.stdout.decode())\n",
    "if result.stderr:\n",
    "    print(result.stderr.decode())\n",
    "\n",
    "# Check if the command was successful\n",
    "if result.returncode == 0:\n",
    "    print(\"Docker container started successfully.\")\n",
    "    # Wait for 15 seconds (adjust as needed)\n",
    "    time.sleep(15)\n",
    "    # Stop the execution of the cell\n",
    "    raise SystemExit(\"Stopped the cell execution. Container is still running.\")\n",
    "else:\n",
    "    print(\"Failed to start the Docker container.\")\n",
    "    print(result.stderr.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9931e7",
   "metadata": {},
   "source": [
    "# To run the same command from terminal if there is an issue while running from the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --rm -it --name new_run -v /Users/abaruah/Documents/HAND_Mac/inundation-mapping/:/foss_fim -v /Users/abaruah/Documents/HAND_Mac/output/:/outputs -v /Users/abaruah/Documents/HAND_Mac/Outputs_temp/:/fim_temp -v /Users/abaruah/Documents/HAND_Mac/Data/:/data sample_inputs:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within the output folder we need to put the downloaded HUC-8 and one csv file fim_inputs.csv. Rename the branch_id.csv file withiin the downloaded HUC-8 (12090301) folder to fim_inputs.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b807985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker run\n",
    "\n",
    "command_to_run_inside_container = \"python foss_fim/tools/inundate_mosaic_wrapper.py -y /outputs -u 12090301 -f /data/Inputs/rating_curve/bankfull_flows/12090301_1stthhour.csv -i /outputs/flood_12090301/inundation_1sthour_trial_.tif\"\n",
    "\n",
    "\n",
    "docker_exec_command = f\"docker exec -it {container_name} {command_to_run_inside_container}\"\n",
    "\n",
    "!{docker_exec_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5675fa",
   "metadata": {},
   "source": [
    "# To run the command from terminal\n",
    "\n",
    "python foss_fim/tools/inundate_mosaic_wrapper.py -y /outputs -u 12090301 -f /data/Inputs/rating_curve/bankfull_flows/12090301_1stthhour.csv -i /outputs/flood_12090301/inundation_1sthour_trial_.tif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3c06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
